{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filePath = \"~/RecSys/ratings_Musical_Instruments.csv\"\n",
    "df = pd.read_csv(filePath,delimiter=\",\")\n",
    "\n",
    "df['tid'] = np.arange(len(df))\n",
    "\n",
    "userMappings = dict(zip(df.user_id.unique(),range(len(df.user_id.unique()))))\n",
    "userRevMapping = {userId:userIdx for (userIdx,userId) in userMappings.items()}\n",
    "\n",
    "df['user_idx'] = df.user_id.apply(lambda x: userMappings[x])\n",
    "\n",
    "itemMappings = dict(zip(df.item_id.unique(),range(len(df.item_id.unique()))))\n",
    "itemRevMapping = {itemId:itemIdx for (itemIdx,itemId) in itemMappings.items()}\n",
    "df['item_idx'] = df.item_id.apply(lambda x: itemMappings[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemGroups = df.groupby('item_id')\n",
    "noRatingsPerItem = itemGroups.apply(len)\n",
    "userGroups = df.groupby('user_id')\n",
    "noRatingsPerUser = userGroups.apply(len)\n",
    "                                    \n",
    "def sampleFrom(x):\n",
    "    #p = noRatingsPerUser.loc[x.user_id]\n",
    "    #p = p / p.sum()\n",
    "    size = int(math.ceil(0.5*len(x)))\n",
    "    return x.iloc[np.random.choice(range(len(x)),size=size)]\n",
    "trainData = df.groupby('user_id').apply(sampleFrom)\n",
    "trainData = df[df.tid.isin(trainData.tid.values) == True]\n",
    "testData = df[df.tid.isin(trainData.tid.values) == False]\n",
    "\n",
    "temp = testData[testData.item_id.isin(trainData.item_id.values) == False]\n",
    "testData = testData[testData.item_id.isin(trainData.item_id.values) == True]\n",
    "trainData = trainData.append(temp)\n",
    "\n",
    "print(\"Size of training set: {0}\".format(len(trainData)))\n",
    "print(\"Size of test set: {0}\".format(len(testData)))\n",
    "print(\"Ratio: {0}/{1}\".format(int(100 * float(len(trainData)) / len(df)),\n",
    "                              int(math.ceil(100 * float(len(testData)) / len(df)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creating tensorflow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "mu = tf.Variable(tf.zeros(1),name='global_bias',dtype=tf.float32)\n",
    "\n",
    "noUsers = len(df.user_id.unique())\n",
    "userBias = tf.Variable(tf.random_uniform([noUsers],minval=0,maxval=1),name='user_bias',dtype=tf.float32)\n",
    "\n",
    "noItems = len(df.item_id.unique())\n",
    "itemBias = tf.Variable(tf.random_uniform([noItems],minval=0,maxval=1),name='item_bias',dtype=tf.float32)\n",
    "\n",
    "latentFactors = 5\n",
    "userFactors = tf.Variable(tf.random_uniform([noUsers, latentFactors],minval=0,maxval=1),\n",
    "                          name='user_factors',dtype=tf.float32)\n",
    "itemFactors = tf.Variable(tf.random_uniform([noItems, latentFactors],minval=0,maxval=1),\n",
    "                          name='item_factors',dtype=tf.float32)\n",
    "\n",
    "userId = tf.placeholder(tf.int32, [None], name='user_id')\n",
    "itemId = tf.placeholder(tf.int32, [None], name='item_id')\n",
    "\n",
    "userBiasLU = tf.nn.embedding_lookup(userBias, userId)\n",
    "userFactorLU = tf.nn.embedding_lookup(userFactors, userId)\n",
    "\n",
    "itemBiasLU = tf.nn.embedding_lookup(itemBias, itemId)\n",
    "itemFactorLU = tf.nn.embedding_lookup(itemFactors, itemId)\n",
    "\n",
    "predRatings = mu + itemBiasLU + userBiasLU + tf.reduce_sum(tf.multiply(itemFactorLU,userFactorLU),axis=1)\n",
    "topKItems = tf.nn.top_k(predRatings,k=10,name='recommendations')\n",
    "actRatings = tf.placeholder(tf.float32,[None],name='actual_ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squaredLoss = tf.losses.mean_squared_error(actRatings,predRatings)\n",
    "rmse = tf.sqrt(squaredLoss)\n",
    "maeLoss = tf.reduce_mean(tf.abs(actRatings - predRatings))\n",
    "\n",
    "userReg = tf.nn.l2_loss(userFactors)\n",
    "itemReg = tf.nn.l2_loss(itemFactors)\n",
    "\n",
    "beta = 0.5\n",
    "loss = maeLoss + beta*userReg + beta*itemReg\n",
    "train_op = tf.contrib.layers.optimize_loss(loss=loss,\n",
    "                                           global_step=tf.contrib.framework.get_global_step(),\n",
    "                                           learning_rate=0.001,\n",
    "                                           optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0\n",
      "\t Training Loss: 101617.01384\n",
      "\n",
      "\n",
      "\t Test RMSE Loss: 2.81927466393\n",
      "\t      MAE Loss: 2.64410972595\n",
      "Episode:  10\n",
      "\t Training Loss: 0.799484325696\n",
      "\n",
      "\n",
      "\t Test RMSE Loss: 1.11149597168\n",
      "\t      MAE Loss: 0.777261018753\n",
      "Episode:  20\n",
      "\t Training Loss: 0.591310235903\n",
      "\n",
      "\n",
      "\t Test RMSE Loss: 1.08298504353\n",
      "\t      MAE Loss: 0.722121059895\n",
      "Episode:  30\n",
      "\t Training Loss: 0.464577709585\n",
      "\n",
      "\n",
      "\t Test RMSE Loss: 1.07900643349\n",
      "\t      MAE Loss: 0.716177523136\n",
      "Episode:  40\n",
      "\t Training Loss: 0.37633929239\n",
      "\n",
      "\n",
      "\t Test RMSE Loss: 1.08269011974\n",
      "\t      MAE Loss: 0.722053468227\n",
      "Episode:  50\n",
      "\t Training Loss: 0.311710931852\n",
      "\n",
      "\n",
      "\t Test RMSE Loss: 1.09157216549\n",
      "\t      MAE Loss: 0.732465028763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-cf7f30d4f806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mitemIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0muserId\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0muserIds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitemId\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mitemIds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactRatings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtrainMetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mepisodeLoss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrainMetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eval_op'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "fetches = {'eval_op':train_op}\n",
    "noEpisodes = 100\n",
    "batchSize = 1000\n",
    "noEpochs = len(trainData) / batchSize\n",
    "\n",
    "testFeed = {userId:testData.user_idx.values,\n",
    "            itemId:testData.item_idx.values,\n",
    "            actRatings:testData.rating.values}\n",
    "\n",
    "prevMAE = 10000\n",
    "prevRMSE = 10000\n",
    "\n",
    "for episode in range(noEpisodes):\n",
    "    episodeData = trainData.iloc[np.random.permutation(len(trainData))]\n",
    "    startIdx = 0\n",
    "    episodeLoss = 0\n",
    "    for epoch in range(noEpochs):\n",
    "        batch = episodeData.iloc[startIdx:startIdx+batchSize]\n",
    "        startIdx += batchSize\n",
    "\n",
    "        labels = batch.rating.values\n",
    "        userIds = batch.user_idx.values\n",
    "        itemIds = batch.item_idx.values\n",
    "        feed_dict = {userId:userIds,itemId:itemIds,actRatings:labels}\n",
    "        trainMetrics = sess.run(fetches,feed_dict)\n",
    "        episodeLoss += trainMetrics['eval_op']\n",
    "\n",
    "    episodeLoss /= noEpochs\n",
    "\n",
    "    if(episode % 10 == 0):\n",
    "        print \"Episode: \",episode\n",
    "        print \"\\t Training Loss: {0}\".format(episodeLoss)\n",
    "        print \"\\n\"\n",
    "\n",
    "        fetches = {'rmse':rmse,'mae':maeLoss}\n",
    "        testMetrics = sess.run(fetches,testFeed)\n",
    "        \n",
    "        if(prevRMSE < testMetrics['rmse'] or prevMAE < testMetrics['mae']):\n",
    "            break\n",
    "        prevRMSE = testMetrics['rmse']\n",
    "        prevMAE = testMetrics['mae']\n",
    "        \n",
    "        fetches = {'eval_op':train_op}\n",
    "        print \"\\t Test RMSE Loss: {0}\".format(testMetrics['rmse'])\n",
    "        print \"\\t      MAE Loss: {0}\".format(testMetrics['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 0\n",
    "for uid in range(1000):\n",
    "    noItemsInTest = len(testData.item_idx.unique())\n",
    "    userFeed = {userId:np.ones((noItemsInTest)) * uid,\n",
    "                itemId:testData.item_idx.unique()}\n",
    "    fetches = {'topK':topKItems}\n",
    "    retVal = sess.run(fetches=fetches,feed_dict=userFeed)\n",
    "    topKRecommendations = retVal['topK']\n",
    "    x = userGroups.get_group(userRevMapping[uid])\n",
    "    lTemp = len(set(x.item_idx.values) & set(topKRecommendations.indices))\n",
    "    if(l < lTemp):\n",
    "        l = lTemp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
